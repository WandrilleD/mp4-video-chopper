{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09cf7573",
   "metadata": {},
   "source": [
    "# automatically annotating silences in a video\n",
    "\n",
    "this notebook is here to automatically annotate any silence lasting more than some duration (e.g. 5 seconds) from a video or audio file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preliminary definitions.\n",
    "## you will have to install the audiosegment python library \n",
    "# !pip install audiosegment\n",
    "\n",
    "\n",
    "import audiosegment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def format_time(a):\n",
    "    hms=[str( a//3600 ),str( (a%3600)//60 ),str( a%60 )]\n",
    "    for i in range(len(hms)):\n",
    "        if len(hms[i])==1:\n",
    "            hms[i] = '0' + hms[i]\n",
    "    \n",
    "    return ':'.join( hms )\n",
    "\n",
    "def getStretch( R ):\n",
    "    \"\"\" finds contiguous windows where a condition is satistied \"\"\"\n",
    "    previous = False\n",
    "    windows = []\n",
    "    for i in range(0,len(R)):\n",
    "        if R[i]:\n",
    "            if not previous :\n",
    "                windows.append([i,i])\n",
    "            else:\n",
    "                windows[-1][-1]=i\n",
    "        previous=R[i]\n",
    "    return windows\n",
    "\n",
    "def get_mean_every( data , every ):\n",
    "    return np.array([ np.mean( np.abs( data[ i*every :(i+1)*every ] ) ) for i in range( math.ceil(len(data)/every) )])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513c7d0",
   "metadata": {},
   "source": [
    "We read the audio and simplify it to get the average sound amplitude at each second \n",
    "(if the video/audio is long, this will take some time, maybe up to a minute so be patient):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d143d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## put here the input file \n",
    "## NB: in example I use a m4a. but this works with a mp4 video too:\n",
    "input_file = \"toy_data/audio2803562588.m4a\"\n",
    "\n",
    "output_file = \"cutout_annotations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d29f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## reading the audio\n",
    "seg = audiosegment.from_file(input_file)\n",
    "print( seg )\n",
    "## from audio segment to numpy arrays:\n",
    "A = seg.to_numpy_array()\n",
    "Ampl_second = get_mean_every( np.abs(A) , seg.frame_rate )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a9f0f",
   "metadata": {},
   "source": [
    "A silence is whenever the amplitude gets below 10 (I found 10 works well, use higher values if the microphone adds some noise or something).\n",
    "\n",
    "We want to remove every silences that last at least 5 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3bfa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## any silence lasting longer than that number (in seconds) will be annotated:\n",
    "SILENCE_DURATION_THRESHOLD = 5 \n",
    "\n",
    "\n",
    "DETECTION_THRESHOLD = 10 # define amplitude under which we say there is silence\n",
    "\n",
    "\n",
    "W = getStretch( Ampl_second< DETECTION_THRESHOLD )\n",
    "\n",
    "starts = []\n",
    "stops = []\n",
    "\n",
    "\n",
    "print( 'start' ,'\\t', 'duration',\" \\tcut out annotation\")\n",
    "for w in W:\n",
    "    if w[1]-w[0] > SILENCE_DURATION_THRESHOLD:\n",
    "        print( w[0] ,'\\t', w[1]-w[0],\n",
    "              \"\\t\\tcut out {} to {}\".format( format_time(w[0]) , format_time(w[1]) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0372b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## writing the cutout instruction to a csv file:\n",
    "with open( output_file , 'w' ) as OUT:\n",
    "    print( 'source' ,'start','stop','destination' , sep=',' , file=OUT)\n",
    "    for w in W:\n",
    "        if w[1]-w[0] > SILENCE_DURATION_THRESHOLD:\n",
    "            print( input_file, format_time(w[0]) , format_time(w[1]) , 'OUT' ,\n",
    "                  sep=',' , file=OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## maybe you want to plot specific streches \n",
    "## of the signal to check the automatic annotation :\n",
    "a,b = 3390,3410\n",
    "plt.plot( A[seg.frame_rate * a: seg.frame_rate * b]  ) ## full signal\n",
    "plt.plot( seg.frame_rate*0.5 + seg.frame_rate * np.arange(b-a) , 1000 * np.log10( Ampl_second[a: b] ) ) # simplified to 1/second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce1d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
